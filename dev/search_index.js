var documenterSearchIndex = {"docs":
[{"location":"manual/linalg/#Linear-Algebra-1","page":"Linear Algebra","title":"Linear Algebra","text":"","category":"section"},{"location":"manual/linalg/#","page":"Linear Algebra","title":"Linear Algebra","text":"GeometricFlux.degrees","category":"page"},{"location":"manual/linalg/#GeometricFlux.degrees","page":"Linear Algebra","title":"GeometricFlux.degrees","text":"degrees(g[, T; dir=:out])\n\nDegree of each vertex. Return a vector which contains the degree of each vertex in graph g.\n\nArguments\n\ng: should be a adjacency matrix, SimpleGraph, SimpleDiGraph (from LightGraphs) or SimpleWeightedGraph, SimpleWeightedDiGraph (from SimpleWeightedGraphs).\nT: result element type of degree vector; default is the element type of g (optional).\ndir: direction of degree; should be :in, :out, or :both (optional).\n\nExamples\n\njulia> using GeometricFlux\n\njulia> m = [0 1 1; 1 0 0; 1 0 0];\n\njulia> GeometricFlux.degrees(m)\n3-element Array{Int64,1}:\n 2\n 1\n 1\n\n\n\n\n\n\n","category":"function"},{"location":"manual/linalg/#","page":"Linear Algebra","title":"Linear Algebra","text":"GeometricFlux.degree_matrix","category":"page"},{"location":"manual/linalg/#GeometricFlux.degree_matrix","page":"Linear Algebra","title":"GeometricFlux.degree_matrix","text":"degree_matrix(g[, T; dir=:out])\n\nDegree matrix of graph g. Return a matrix which contains degrees of each vertex in its diagonal. The values other than diagonal are zeros.\n\nArguments\n\ng: should be a adjacency matrix, FeaturedGraph, SimpleGraph, SimpleDiGraph (from LightGraphs) or SimpleWeightedGraph, SimpleWeightedDiGraph (from SimpleWeightedGraphs).\nT: result element type of degree vector; default is the element type of g (optional).\ndir: direction of degree; should be :in, :out, or :both (optional).\n\nExamples\n\njulia> using GeometricFlux\n\njulia> m = [0 1 1; 1 0 0; 1 0 0];\n\njulia> GeometricFlux.degree_matrix(m)\n3×3 SparseArrays.SparseMatrixCSC{Int64,Int64} with 3 stored entries:\n  [1, 1]  =  2\n  [2, 2]  =  1\n  [3, 3]  =  1\n\n\n\n\n\n","category":"function"},{"location":"manual/linalg/#","page":"Linear Algebra","title":"Linear Algebra","text":"GeometricFlux.inv_sqrt_degree_matrix","category":"page"},{"location":"manual/linalg/#GeometricFlux.inv_sqrt_degree_matrix","page":"Linear Algebra","title":"GeometricFlux.inv_sqrt_degree_matrix","text":"inv_sqrt_degree_matrix(g[, T; dir=:out])\n\nInverse squared degree matrix of graph g. Return a matrix which contains inverse squared degrees of each vertex in its diagonal. The values other than diagonal are zeros.\n\nArguments\n\ng: should be a adjacency matrix, FeaturedGraph, SimpleGraph, SimpleDiGraph (from LightGraphs) or SimpleWeightedGraph, SimpleWeightedDiGraph (from SimpleWeightedGraphs).\nT: result element type of degree vector; default is the element type of g (optional).\ndir: direction of degree; should be :in, :out, or :both (optional).\n\n\n\n\n\n","category":"function"},{"location":"manual/linalg/#","page":"Linear Algebra","title":"Linear Algebra","text":"GeometricFlux.laplacian_matrix","category":"page"},{"location":"manual/linalg/#GeometricFlux.laplacian_matrix","page":"Linear Algebra","title":"GeometricFlux.laplacian_matrix","text":"laplacian_matrix(g[, T; dir=:out])\n\nLaplacian matrix of graph g.\n\nArguments\n\ng: should be a adjacency matrix, FeaturedGraph, SimpleGraph, SimpleDiGraph (from LightGraphs) or SimpleWeightedGraph, SimpleWeightedDiGraph (from SimpleWeightedGraphs).\nT: result element type of degree vector; default is the element type of g (optional).\ndir: direction of degree; should be :in, :out, or :both (optional).\n\n\n\n\n\n","category":"function"},{"location":"manual/linalg/#","page":"Linear Algebra","title":"Linear Algebra","text":"GeometricFlux.normalized_laplacian","category":"page"},{"location":"manual/linalg/#GeometricFlux.normalized_laplacian","page":"Linear Algebra","title":"GeometricFlux.normalized_laplacian","text":"normalized_laplacian(g[, T; selfloop=false])\n\nNormalized Laplacian matrix of graph g.\n\nArguments\n\ng: should be a adjacency matrix, FeaturedGraph, SimpleGraph, SimpleDiGraph (from LightGraphs) or SimpleWeightedGraph, SimpleWeightedDiGraph (from SimpleWeightedGraphs).\nT: result element type of degree vector; default is the element type of g (optional).\nselfloop: adding self loop while calculating the matrix (optional).\n\n\n\n\n\n","category":"function"},{"location":"manual/models/#Models-1","page":"Models","title":"Models","text":"","category":"section"},{"location":"manual/pool/#Pooling-layers-1","page":"Pooling Layers","title":"Pooling layers","text":"","category":"section"},{"location":"manual/conv/#Convolution-Layers-1","page":"Convolutional Layers","title":"Convolution Layers","text":"","category":"section"},{"location":"manual/conv/#Graph-Convolutional-Layer-1","page":"Convolutional Layers","title":"Graph Convolutional Layer","text":"","category":"section"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"X = sigma(hatD^-12 hatA hatD^-12 X Theta)","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"where hatA = A + I, A denotes the adjacency matrix, and hatD = hatd_ij = sum_j=0 hata_ij is degree matrix.","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"GCNConv","category":"page"},{"location":"manual/conv/#GeometricFlux.GCNConv","page":"Convolutional Layers","title":"GeometricFlux.GCNConv","text":"GCNConv([graph, ]in=>out)\nGCNConv([graph, ]in=>out, σ)\n\nGraph convolutional layer.\n\nArguments\n\ngraph: should be a adjacency matrix, SimpleGraph, SimpleDiGraph (from LightGraphs) \n\nor SimpleWeightedGraph, SimpleWeightedDiGraph (from SimpleWeightedGraphs). Is optionnal so you can give a FeaturedGraph to the layer instead of only the features.\n\nin: the dimension of input features.\nout: the dimension of output features.\nbias::Bool=true: keyword argument, whether to learn the additive bias.\n\nData should be stored in (# features, # nodes) order. For example, a 1000-node graph each node of which poses 100 features is constructed. The input data would be a 1000×100 array.\n\n\n\n\n\n","category":"type"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"Reference: Semi-supervised Classification with Graph Convolutional Networks","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"","category":"page"},{"location":"manual/conv/#Chebyshev-Spectral-Graph-Convolutional-Layer-1","page":"Convolutional Layers","title":"Chebyshev Spectral Graph Convolutional Layer","text":"","category":"section"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"X = sum^K-1_k=0 Z^(k) Theta^(k)","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"where Z^(k) is the k-th term of Chebyshev polynomials, and can be calculated by the following recursive form:","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"Z^(0) = X \nZ^(1) = hatL X \nZ^(k) = 2 hatL Z^(k-1) - Z^(k-2)","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"and hatL = frac2lambda_max L - I.","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"ChebConv","category":"page"},{"location":"manual/conv/#GeometricFlux.ChebConv","page":"Convolutional Layers","title":"GeometricFlux.ChebConv","text":"ChebConv([graph, ]in=>out, k)\n\nChebyshev spectral graph convolutional layer.\n\nArguments\n\ngraph: should be a adjacency matrix, SimpleGraph, SimpleDiGraph (from LightGraphs) or SimpleWeightedGraph, \n\nSimpleWeightedDiGraph (from SimpleWeightedGraphs). Is optionnal so you can give a FeaturedGraph to the layer instead of only the features.\n\nin: the dimension of input features.\nout: the dimension of output features.\nk: the order of Chebyshev polynomial.\nbias::Bool=true: keyword argument, whether to learn the additive bias.\n\n\n\n\n\n","category":"type"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"Reference: Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"","category":"page"},{"location":"manual/conv/#Graph-Neural-Network-Layer-1","page":"Convolutional Layers","title":"Graph Neural Network Layer","text":"","category":"section"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"textbfx_i = Theta_1 textbfx_i + sum_j in mathcalN(i) Theta_2 textbfx_j","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"GraphConv","category":"page"},{"location":"manual/conv/#GeometricFlux.GraphConv","page":"Convolutional Layers","title":"GeometricFlux.GraphConv","text":"GraphConv([graph, ]in=>out)\nGraphConv([graph, ]in=>out, aggr)\n\nGraph neural network layer.\n\nArguments\n\ngraph: should be a adjacency matrix, SimpleGraph, SimpleDiGraph (from LightGraphs) or SimpleWeightedGraph, \n\nSimpleWeightedDiGraph (from SimpleWeightedGraphs). Is optionnal so you can give a FeaturedGraph to the layer instead of only the features.\n\nin: the dimension of input features.\nout: the dimension of output features.\nbias::Bool=true: keyword argument, whether to learn the additive bias.\naggr::Symbol=:add: an aggregate function applied to the result of message function. :add, :max and :mean are available.\n\n\n\n\n\n","category":"type"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"Reference: Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"","category":"page"},{"location":"manual/conv/#Graph-Attentional-Layer-1","page":"Convolutional Layers","title":"Graph Attentional Layer","text":"","category":"section"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"textbfx_i = alpha_ii Theta textbfx_i + sum_j in mathcalN(i) alpha_ij Theta textbfx_j","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"where the attention coefficient alpha_ij can be calculated from","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"alpha_ij = fracexp(LeakyReLU(textbfa^T Theta textbfx_i  Theta textbfx_j))sum_k in mathcalN(i) cup i exp(LeakyReLU(textbfa^T Theta textbfx_i  Theta textbfx_k))","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"GATConv","category":"page"},{"location":"manual/conv/#GeometricFlux.GATConv","page":"Convolutional Layers","title":"GeometricFlux.GATConv","text":"GATConv([graph, ]in=>out)\n\nGraph attentional layer.\n\nArguments\n\ngraph: should be a adjacency matrix, SimpleGraph, SimpleDiGraph (from LightGraphs) or SimpleWeightedGraph, \n\nSimpleWeightedDiGraph (from SimpleWeightedGraphs). Is optionnal so you can give a FeaturedGraph to the layer instead of only the features.\n\nin: the dimension of input features.\nout: the dimension of output features.\nbias::Bool=true: keyword argument, whether to learn the additive bias.\nnegative_slope::Real=0.2: keyword argument, the parameter of LeakyReLU.\n\n\n\n\n\n","category":"type"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"Reference: Graph Attention Networks","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"","category":"page"},{"location":"manual/conv/#Gated-Graph-Convolution-Layer-1","page":"Convolutional Layers","title":"Gated Graph Convolution Layer","text":"","category":"section"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"textbfh^(0)_i = textbfx_i  textbf0 \ntextbfh^(l)_i = GRU(textbfh^(l-1)_i sum_j in mathcalN(i) Theta textbfh^(l-1)_j)","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"where textbfh^(l)_i denotes the l-th hidden variables passing through GRU. The dimension of input textbfx_i needs to be less or equal to out.","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"GatedGraphConv","category":"page"},{"location":"manual/conv/#GeometricFlux.GatedGraphConv","page":"Convolutional Layers","title":"GeometricFlux.GatedGraphConv","text":"GatedGraphConv([graph, ]out, num_layers)\n\nGated graph convolution layer.\n\nArguments\n\ngraph: should be a adjacency matrix, SimpleGraph, SimpleDiGraph (from LightGraphs) or SimpleWeightedGraph, \n\nSimpleWeightedDiGraph (from SimpleWeightedGraphs). Is optionnal so you can give a FeaturedGraph to the layer instead of only the features.\n\nout: the dimension of output features.\nnum_layers specifies the number of gated recurrent unit.\naggr::Symbol=:add: an aggregate function applied to the result of message function. :add, :max and :mean are available.\n\n\n\n\n\n","category":"type"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"Reference: Gated Graph Sequence Neural Networks","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"","category":"page"},{"location":"manual/conv/#Edge-Convolutional-Layer-1","page":"Convolutional Layers","title":"Edge Convolutional Layer","text":"","category":"section"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"textbfx_i = sum_j in mathcalN(i) f_Theta(textbfx_i  textbfx_j - textbfx_i)","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"where f_Theta denotes a neural network parametrized by Theta, i.e., a MLP.","category":"page"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"EdgeConv","category":"page"},{"location":"manual/conv/#GeometricFlux.EdgeConv","page":"Convolutional Layers","title":"GeometricFlux.EdgeConv","text":"EdgeConv(graph, nn)\nEdgeConv(graph, nn, aggr)\n\nEdge convolutional layer.\n\nArguments\n\ngraph: should be a adjacency matrix, SimpleGraph, SimpleDiGraph (from LightGraphs) or SimpleWeightedGraph, SimpleWeightedDiGraph (from SimpleWeightedGraphs).\nnn: a neural network\naggr::Symbol=:max: an aggregate function applied to the result of message function. :add, :max and :mean are available.\n\n\n\n\n\n","category":"type"},{"location":"manual/conv/#","page":"Convolutional Layers","title":"Convolutional Layers","text":"Reference: Dynamic Graph CNN for Learning on Point Clouds","category":"page"},{"location":"#GeometricFlux:-The-Geometric-Deep-Learning-Library-in-Julia-1","page":"Home","title":"GeometricFlux: The Geometric Deep Learning Library in Julia","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Documentation for GeometricFlux.jl","category":"page"},{"location":"#Installation-1","page":"Home","title":"Installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"] add GeometricFlux","category":"page"},{"location":"#Quick-start-1","page":"Home","title":"Quick start","text":"","category":"section"},{"location":"manual/utils/#Utilities-1","page":"Utilities","title":"Utilities","text":"","category":"section"},{"location":"manual/utils/#","page":"Utilities","title":"Utilities","text":"GeometricFlux.save_div","category":"page"},{"location":"manual/utils/#GeometricFlux.save_div","page":"Utilities","title":"GeometricFlux.save_div","text":"save_div(x, y)\n\nSavely divde x by y. If y is zero, return x directly.\n\n\n\n\n\n","category":"function"}]
}
